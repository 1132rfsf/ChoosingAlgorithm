import os
import sys

# ==========================================
# 1. ç¯å¢ƒé…ç½®
# ==========================================
os.environ['PYSPARK_PYTHON'] = sys.executable
os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable
os.environ['HADOOP_HOME'] = "C:\\hadoop"

# ==========================================
# 2. å¯¼å…¥ä¾èµ–
# ==========================================
from pyspark.sql import SparkSession
from pyspark.sql.functions import udf, col, lit, desc, avg, round, count, collect_list
from pyspark.sql.types import FloatType, StringType, IntegerType
from sentence_transformers import SentenceTransformer, util
import math

def main():
    # åˆå§‹åŒ– Spark
    spark = SparkSession.builder \
        .appName("KaoyanGaussianRec") \
        .master("local[*]") \
        .config("spark.driver.memory", "4g") \
        .getOrCreate()
    spark.sparkContext.setLogLevel("ERROR")

    # ======================================================
    # === ç”¨æˆ·è¾“å…¥é…ç½® ===
    # ======================================================
    user_input = {
        "target_major": "åŒ»å­¦",  
        "exam_history": {
            2021: 320,
            2022: 330,
            2023: 345
        },
        "weight_major": 0.5, # ç¨å¾®é™ä½ä¸“ä¸šæƒé‡ï¼Œè®©èƒœç®—æƒé‡æ›´çªå‡º
        "weight_score": 0.5
    }
    
    target_years = list(user_input["exam_history"].keys())
    print(f"\n>>> ğŸ¯ ç›®æ ‡ä¸“ä¸šï¼š'{user_input['target_major']}'")
    print(f">>> ğŸ“ æ¨¡æ‹ŸçœŸé¢˜æˆç»©ï¼š{user_input['exam_history']}")

    # ======================================================
    # === åŠ è½½æ•°æ® ===
    # ======================================================
    print("\n>>> [1/5] æ­£åœ¨åŠ è½½æ•°æ®...")
    csv_path = "åˆ†æ•°çº¿æ•°æ®.csv"
    if not os.path.exists(csv_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ '{csv_path}'ã€‚")
        return

    df_raw = spark.read.option("header", "true").option("inferSchema", "true").csv(csv_path)

    # æ¸…æ´—æ•°æ®
    df_clean = df_raw.select(
        col("å¹´ä»½").alias("year"),
        col("å­¦æ ¡åç§°").alias("uni_name"),
        col("ä¸“ä¸šåç§°").alias("major_name"),
        col("æ€»åˆ†").cast("double").alias("score_line")
    ).filter(
        col("score_line").isNotNull() & 
        col("major_name").isNotNull() &
        col("year").isin(target_years)
    )

    # ======================================================
    # === ã€æ ¸å¿ƒä¼˜åŒ–ã€‘é’Ÿå½¢æ›²çº¿è¯„åˆ†é€»è¾‘ (Gaussian Scoring) ===
    # ======================================================
    print(">>> [2/5] æ­£åœ¨è¿›è¡Œé’Ÿå½¢æ›²çº¿èƒœç®—è¯„ä¼° (Gaussian Scoring)...")

    broadcast_user_scores = spark.sparkContext.broadcast(user_input["exam_history"])

    def calculate_yearly_prob(year, line):
        user_score = broadcast_user_scores.value.get(year)
        if user_score is None or line is None:
            return 0.0
        
        diff = user_score - line
        
        # --- é’Ÿå½¢æ›²çº¿é€»è¾‘ ---
        if diff == 0:
            return 100.0
        elif diff < 0:
            # ã€å·¦ä¾§ï¼šé£é™©åŒºã€‘
            # åˆ†æ•°ä¸å¤Ÿï¼Œé£é™©æå¤§ï¼Œæ›²çº¿éœ€è¦é™¡å³­ä¸‹é™
            # è®¾å®šï¼šå·® 10 åˆ† -> å¾—åˆ†çº¦ 60 (åŠæ ¼çº¿)
            # å…¬å¼æ¨å¯¼ï¼š60 = 100 * exp(-100/sigma_left) => sigma_left â‰ˆ 200
            sigma = 200.0
            return 100.0 * math.exp(-(diff**2) / sigma)
        else:
            # ã€å³ä¾§ï¼šæ€§ä»·æ¯”åŒºã€‘
            # åˆ†æ•°è¶…äº†ï¼Œè™½ç„¶ç¨³ï¼Œä½†æ€§ä»·æ¯”é™ä½ï¼ˆé«˜åˆ†ä½æŠ¥ï¼‰ï¼Œæ›²çº¿ç¼“æ…¢ä¸‹é™
            # è®¾å®šï¼šé«˜ 50 åˆ† -> å¾—åˆ†çº¦ 50 (å¤ªäºäº†ï¼Œä½†ä¹Ÿç»™æ¨è)
            # å…¬å¼æ¨å¯¼ï¼š50 = 100 * exp(-2500/sigma_right) => sigma_right â‰ˆ 3600
            sigma = 3600.0
            return 100.0 * math.exp(-(diff**2) / sigma)

    udf_yearly_prob = udf(calculate_yearly_prob, FloatType())

    # è®¡ç®—
    df_with_prob = df_clean.withColumn(
        "single_year_prob", 
        udf_yearly_prob(col("year"), col("score_line"))
    )

    df_aggregated = df_with_prob.groupBy("uni_name", "major_name").agg(
        round(avg("single_year_prob"), 1).alias("avg_prob_score"), 
        round(avg("score_line"), 1).alias("avg_line"),             
        count("year").alias("valid_years_count")                   
    )

    # ======================================================
    # === AI è¯­ä¹‰åŒ¹é… (Driverç«¯é¢„è®¡ç®—) ===
    # ======================================================
    print("\n>>> [3/5] æ­£åœ¨è¿›è¡Œ AI è¯­ä¹‰åŒ¹é…...")
    
    distinct_majors_rows = df_aggregated.select("major_name").distinct().collect()
    distinct_majors = [row.major_name for row in distinct_majors_rows if row.major_name]

    model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
    target_embedding = model.encode(user_input["target_major"], convert_to_tensor=True)
    
    score_map = {}
    for major in distinct_majors:
        if len(major) > 20: 
            score_map[major] = 0.0
            continue
        candidate_embedding = model.encode(major, convert_to_tensor=True)
        score = util.cos_sim(target_embedding, candidate_embedding).item()
        if score > 0:
            score_map[major] = float(score)
        else:
            score_map[major] = 0.0
            
    broadcast_ai_scores = spark.sparkContext.broadcast(score_map)

    # ======================================================
    # === ç»¼åˆæ¨è ===
    # ======================================================
    print("\n>>> [4/5] æ­£åœ¨ç”Ÿæˆæœ€ç»ˆæ¦œå•...")

    def get_ai_score(major):
        return broadcast_ai_scores.value.get(major, 0.0)
    udf_ai_lookup = udf(get_ai_score, FloatType())

    df_final = df_aggregated.withColumn(
        "ai_match_score", 
        udf_ai_lookup(col("major_name"))
    ).withColumn(
        "composite_score",
        (col("ai_match_score") * 100 * user_input["weight_major"]) + 
        (col("avg_prob_score") * user_input["weight_score"])
    )

    # ç­›é€‰ï¼š
    # 1. å¿…é¡»ç›¸å…³ (AI > 0.5)
    # 2. å½•å–èƒœç®—åˆ†å¿…é¡» > 40 (é˜²æ­¢æ¨èé‚£äº›å®Œå…¨æ²¡å¸Œæœ›çš„ï¼Œæˆ–è€…æå…¶äºåˆ†çš„)
    top_recommendations = df_final \
        .filter((col("ai_match_score") > 0.5) & (col("avg_prob_score") > 40)) \
        .orderBy(desc("composite_score")) \
        .limit(10)

    print("\n" + "="*120)
    print(f" ğŸ“Š è¯„åˆ†æ¨¡å‹ï¼šä¸å¯¹ç§°é«˜æ–¯åˆ†å¸ƒ (Bell Curve)")
    print(f"    - å®Œç¾åŒºé—´ï¼šåˆ†å·® 0~10 åˆ† (å¾—åˆ† 95-100)")
    print(f"    - é£é™©æƒ©ç½šï¼šåˆ†å·® < -10 åˆ† (å¾—åˆ†æ€¥é€Ÿé™è‡³60ä»¥ä¸‹)")
    print(f"    - æµªè´¹æƒ©ç½šï¼šåˆ†å·® > 50 åˆ† (å¾—åˆ†ç¼“æ…¢é™è‡³50å·¦å³ï¼Œé¿å…é«˜åˆ†ä½æŠ¥)")
    print("="*120)
    
    top_recommendations.select(
        col("uni_name").alias("å­¦æ ¡"), 
        col("major_name").alias("ä¸“ä¸š"), 
        col("avg_line").alias("å†å²å‡åˆ†"),
        col("valid_years_count").alias("å‚è€ƒå¹´æ•°"),
        col("avg_prob_score").alias("å½•å–æ¨èåº¦(0-100)"),
        col("ai_match_score").alias("ä¸“ä¸šå¥‘åˆåº¦"), 
        col("composite_score").alias("â˜…ç»¼åˆæ¨èæŒ‡æ•°")
    ).show(truncate=False)

    spark.stop()

if __name__ == "__main__":
    main()
